{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c739a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import Config\n",
    "from utils import seed_all, ensure_dirs, device\n",
    "from dataset import ImageFolderDataset\n",
    "from models.ie_gan import Generator, Discriminator, IdentityEncoder\n",
    "\n",
    "def train():\n",
    "    cfg = Config()\n",
    "    seed_all(42)\n",
    "    ensure_dirs(cfg.out_root, cfg.out_root/\"checkpoints\")\n",
    "\n",
    "    dev = device()\n",
    "    ds = ImageFolderDataset(cfg.data_root/\"train\", img_size=cfg.img_size, augment=True)\n",
    "    dl = DataLoader(ds, batch_size=cfg.gan_batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
    "\n",
    "    G = Generator(z_dim=cfg.z_dim).to(dev)\n",
    "    D = Discriminator().to(dev)\n",
    "\n",
    "    # Frozen identity encoder\n",
    "    id_enc = IdentityEncoder().to(dev)\n",
    "    for p in id_enc.parameters():\n",
    "        p.requires_grad = False\n",
    "    id_enc.eval()\n",
    "\n",
    "    optG = torch.optim.Adam(G.parameters(), lr=cfg.gan_lr, betas=(0.5, 0.999))\n",
    "    optD = torch.optim.Adam(D.parameters(), lr=cfg.gan_lr, betas=(0.5, 0.999))\n",
    "\n",
    "    for epoch in range(cfg.gan_epochs):\n",
    "        G.train(); D.train()\n",
    "        pbar = tqdm(dl, desc=f\"IE-GAN Epoch {epoch+1}/{cfg.gan_epochs}\")\n",
    "\n",
    "        for real, _ in pbar:\n",
    "            real = real.to(dev)\n",
    "            b = real.size(0)\n",
    "\n",
    "            z = torch.randn(b, cfg.z_dim, device=dev)\n",
    "            fake = G(z).detach()\n",
    "\n",
    "            # label smoothing\n",
    "            real_label = torch.ones(b, 1, device=dev) * (1.0 - cfg.label_smoothing)\n",
    "            fake_label = torch.zeros(b, 1, device=dev)\n",
    "\n",
    "            D_real = D(real)\n",
    "            D_fake = D(fake)\n",
    "\n",
    "            lossD = F.binary_cross_entropy_with_logits(D_real, real_label) + \\\n",
    "                    F.binary_cross_entropy_with_logits(D_fake, fake_label)\n",
    "\n",
    "            optD.zero_grad()\n",
    "            lossD.backward()\n",
    "            optD.step()\n",
    "\n",
    "            # Train Generator\n",
    "            z = torch.randn(b, cfg.z_dim, device=dev)\n",
    "            gen = G(z)\n",
    "            D_gen = D(gen)\n",
    "\n",
    "            adv_loss = F.binary_cross_entropy_with_logits(D_gen, torch.ones(b,1,device=dev))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                real_id = id_enc(real)\n",
    "            gen_id = id_enc(gen)\n",
    "            id_loss = F.l1_loss(gen_id, real_id)\n",
    "\n",
    "            cons_loss = gen_id.var(dim=0).mean()\n",
    "\n",
    "            lossG = adv_loss + cfg.lambda_id * id_loss + 0.1 * cons_loss\n",
    "\n",
    "            optG.zero_grad()\n",
    "            lossG.backward()\n",
    "            optG.step()\n",
    "\n",
    "            pbar.set_postfix({\"D\": float(lossD), \"G\": float(lossG)})\n",
    "\n",
    "    ckpt = {\"G\": G.state_dict(), \"D\": D.state_dict()}\n",
    "    torch.save(ckpt, cfg.gan_ckpt)\n",
    "    print(\"Saved:\", cfg.gan_ckpt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
